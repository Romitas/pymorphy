Как работает pymorphy
#####################

Общая информация
================

pymorphy - библиотека для морфологического анализа на Python,
распространяется по лицензии MIT.

За основу взяты наработки с сайта aot.ru.
Словари (LGPL) для русского и английского, а также идеи - оттуда.
Там были описаны и конкретные алгоритмы реализации, но в терминах
теории автоматов. Реализация в pymorphy независимая, не использует
конечные автоматы, данные хранятся в key-value хранилище (поддерживаются разные
варианты), все алгоритмы переписаны с учетом этого факта.


Возможности библиотеки
----------------------

1. Приводит слово к нормальной форме (например, в ед.ч.,
   И.п. для существительных) - для слова "ЛЮДЕЙ" она должна вернуть "ЧЕЛОВЕК"

2. Определяет форму слова (или формы). Например, для слова "ЛЮДЕЙ" она
   должна как-то дать знать, что это существительное, во множественном числе,
   может оказаться в родительном или винительном падежах.

3. Умеет склонять слова (менять число, падеж и т.д.). В стадии реализации.

Cловари aot.ru
==============

Словари с сайта aot.ru содержат следующую информацию:

1. парадигмы слов и конкретные правила образования;
2. ударения;
3. пользовательские сессии;
4. набор префиксов (продуктивных приставок);
5. леммы (незменяемые части слова, основы);
6. грамматическая информация - в отдельном файле.

Из этого всего нам интересны правила образования слов, префиксы, леммы и
грамматическая информация.

Все слова образуются по одному принципу::

[префикс]+[приставка]+[основа]+[окончание]

.. glossary::

    Префиксы
        Префиксы - это всякие "мега", "супер" и т.д. Набор префиксов хранится просто
        списком.

    Приставки
        Имеются в виду приставки, присущие грамматической форме,
        но не присущие неизменяемой части слова ("по", "наи"). Например, "наи"
        в слове "наикрасивейший", т.к. без превосходной степени будет "красивый".

    Правила образования слов
        Это то, что надо приписать спереди и сзади основы,
        чтобы получить какую-то форму. В словаре хранятся пары
        "приставка - окончание", + "номер" записи о грамматической информации
        (которая хранится отдельно).

    Парадигмы
        Правила образования слов объединены в *парадигмы*. Например, для какого-нибудь
        класса существительных может быть описано, как слово выглядит во всех падежах
        и родах. Зная, что существительное принадлежит к этому классу, мы сможем
        правильно получить любую его форму. Такой класс - это и есть парадигма. [#]_

    Леммы
        Леммы - это неизменяемые части слов. В словаре хранится информация о том,
        какой лемме соответствуют какие парадигмы (какой набор правил для образования
        грамматических форм слова). Одной лемме может соответствовать несколько парадигм.

    Грамматическая информация
        Грамматическая информация - просто пары ("номер" записи, грам. информация).
        "Номер" в кавычках, т.к. это 2 буквы, просто от балды, но все разные.

Файл со словарем - обычный текстовый, для каждого раздела сначала указано
число строк в нем, а потом идут строки, формат их описан тут.

Поняв структуру словаря, можно написать первую версию морфологического анализатора.

Морфологический анализатор
==========================

По сути, нам дано слово, и его надо найти среди всех разумных комбинаций вида::

    <префикс>+<приставка>+<лемма>+<окончание>

и::

    <приставка>+<лемма>+<окончание>

Дело упрощает то, что оказалось (как показала пара строчек на питоне),
что "приставок" у нас в языке (да и в английском вроде тоже) всего 2.
А префиксов в словаре - порядка 20 для русского языка. Поэтому искать
можно среди комбинаций::

    <префикс>+<лемма>+<окончание>,

объединив в уме список приставок и префиксов, а затем выполнив
небольшую проверочку.

Если слово начинается с одного из возможных префиксов,
то мы его (префикс) отбрасываем и пытаемся морфологически
анализировать остаток (рекурсивно), а потом просто припишем
отброшенный префикс к полученным формам.

В итоге получается, что задача сводится к поиску среди комбинаций::

    <лемма>+<окончание>

Ищем подходящие леммы, потом смотрим, есть ли для них подходящие окончания. [#f1]_

Для поиска задействован стандартный питоновский ассоциативный массив (dict,
или любой объект, поддерживающий ``__getitem__``, ``__setitem__`` и ``__contains__``),
в который поместил все леммы. Получился словарь вида::

    lemmas: {base -> [rule_id]}

т.е. ключ - это лемма, а значение - список номеров допустимых парадигм.
А дальше поехали - сначала считаем, что лемма - это первая буква слова,
потом, что это 2 первых буквы и т.д. По лемме пытаемся получить список
парадигм. Если получили, то в каждой допустимой парадигме пробегаем по
всем правилам и смотрим, получится ли наше слово, если правило применить.
Получается - добавляем его в список найденных форм.


Дополнительные детали работы морфологического анализатора
---------------------------------------------------------

Слова без неизменяемой части
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Если вспомнить пример, который был в начале, про "ЛЮДЕЙ" - "ЧЕЛОВЕК", то
станет понятно, что есть слова, у которых неизменяемая часть отсутствует.
Выяснилось, что есть в словаре такая хитрая магическая лемма "#", которая и
соответствует всем пустым леммам. Для всех слов нужно искать еще и там.

Предсказатель
-------------

Реализован "предсказатель", который может работать со словами,
которых нет в словаре. Это не только неизвестные науке редкие слова,
но и просто описки, например.

Для предсказателя реализованы 2 подхода, которые работают совместно.

Первый подход: угадывание префикса
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Если слова отличаются только тем, что к одному из них приписано
что-то спереди, то, скорее всего, склоняться они будут однаково.

Реализуется очень просто: пробуем считать сначала одну первую букву
слова префиксом, потом 2 первых буквы и т.д. А то, что осталось,
передаем морфологическому анализатору. Ну и делаем это только для не очень
длинных префиксов и не очень коротких остатков.

Второй подход: предсказание по концу слова
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Если 2 слова оканчиваются одинаково, то и склоняться они, скорее всего,
будут одинаково.

Второй подход чуть сложнее в реализации (так-то сильно сложнее, если нужна
хорошая реализация)) и "поумнее" в плане предсказаний.

Первая сложность связана с тем, что конец слова может состоять не только из
окончания, но и из части леммы. Для простоты тут задействован опять
ассоциативный массив (или duck typing-заменитель) с предварительно
подготовленными всеми возмоными окончаниями слов (до 5 букв).
Их получилось несколько сот тысяч. Ключ массива - конец слова, значение -
список возможных правил. Дальше - все как при поиске подходящей леммы,
только у слова берем не начало, а 1, 2, 3, 4, 5-буквенные концы, а вместо лемм
у нас теперь новый монстромассив.

Вторая сложность - получается много заведомого мусора. Мусор этот отсекается,
если учесть, что полученные слова могут быть только существительными,
прилагательными, наречиями или глаголами.

Даже после этого у нас остается слишком много не-мусорных правил.
Для определенности, для каждой части речи оставляем только самое
распространенное правило.
По идее, если слово не было предсказано как существительное,
хорошо бы добавить вариант с неизменяемым существительным
в ед.ч. и.п., но это сейчас не реализовано.

Key-value базы данных для хранения словарей
===========================================

В алгоритмах использовались данные в виде ассоциативных и простых
массивов. Чтобы не загружать все словари сразу в память, в pymorphy
данные берутся из одной из key-value базы данных. Интерфейс доступа
при этом остается как для dict. Т.е. требование к хранилищу - поддерживать
``[]`` и ``in`` (``__getitem__``, ``__setitem__`` и ``__contains__``).


.. _supported-storages:

Поддерживаемые типы хранилищ
----------------------------

Shelve
^^^^^^

Это включенная в стандартную поставку библиотека, которая предоставляет
dict-like доступ к базам данных BSDDB, GDB, BDB и DumbDB.

Плюс - включена в стандартную поставку и потребляет меньше всего
оперативной памяти.

Минус - меньшая скорость работы, чем у  альтернативных вариантов,
часто меняющийся (от версии к версии) формат баз BSDDB. Из-за этого нельзя
просто дать ссылку на скачивание словаря в нужном формате, а следует
переконвертировать словари каждый раз на конкретной машине для текущей
версии BSDDB.

Еще минус - словари занимают больше места на диске (раза в полтора-два), чем при
использовании других DB.

.. note::

    Файлы со словарями имеют расширение ".shelve".

Tokyo Cabinet
^^^^^^^^^^^^^

http://1978th.net/tokyocabinet/

Наследник BSDDB, BDB, GDBM, QDBM. Обеспечивает хорошую скорость работы и
небольшой размер словарей. Лицензия LGPL.

Требует установки tokyocabinet средствами ОС.

debian ::

    $ sudo aptitude install tokyocabinet-bin
    $ pip install pytc

macports ::

    $ sudo port install tokyocabinet
    $ pip install pytc

.. note::

    Файлы со словарями имеют расширение ".tcb" и ".tch" для Btree+ и Hash-вариантов
    базы. Btree занимает меньше места, но работает чуть медленнее.

CDB
^^^

http://cr.yp.to/cdb.html
http://pilcrow.madison.wi.us/

Самый быстрый вариант, ест меньше памяти, чем Tokyo Cabinet, автор
D. J. Bernstein.

Установка::

    $ pip install python-cdb

Для установки потребуются установленные средства сборки (gcc, заголовочные
файлы питона).

Минус - лицензия GPL. А pymorphy - под лицензией MIT. И я вот не знаю, можно
ли вообще его использовать.

.. note::

    Файлы со словарями имеют расширение ".cdb"


Выбор хранилища
---------------

Очень мало оперативной памяти: Shelve (BSDDB), отключаем кеширование и psyco.

Достаточно оперативной памяти, нужна большая скорость: CDB или Tokyo Cabinet,
включаем кеширование и psyco.

Какие-то проблемы при установке CDB или TC (технические или лицензионного
характера): Shelve, кеширование и psyco включены.

psyco обычно добавляет 1М к занимаемой оперативной памяти и ускоряет работу раза
в 2.

Кеширование _сильно_ ускоряет работу, но увеличивает потребление памяти в
соответствии с тем, сколько разных слов было запрошено.

CDB и Tokyo Cabinet быстрее BSDDB процентов на 20-50.



.. rubric:: Примечания

.. [#] В pymorphy считается, что первой в парадигме всегда идет нормальная форма
       слова. Это правило эмпирическое и не всегда правильное.
       Тут желательно что-то придумать.

.. [#] Еще был вариант - составить сразу словарь всех возможных слов
       вида ``<лемма>+<окончание>``, получалось в итоге где-то миллионов 5
       слов, не так и много, но вариант, вообщем, мне не очень понравился.
